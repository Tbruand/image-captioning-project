import os
import torch
from torch import nn, optim
from torch.utils.data import random_split, DataLoader
from src.data.dataset import ImageCaptionDataset, get_collate_fn
from src.data.tokenizer import load_tokenizer
from src.model.decoder import DecoderWithAttention
from src.train.engine import train_model
from src.train.metrics import compute_bleu, compute_rouge
import yaml

# ğŸ“– Chargement de la config
with open("config/config.yaml", "r") as f:
    config = yaml.safe_load(f)

# ğŸ§  Device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸš€ Training started on {device}")

# ğŸ“¦ Dataset & Tokenizer
tokenizer = load_tokenizer(config["tokenizer_path"])

from pathlib import Path
import json

# ğŸ“– Chargement des captions alignÃ©es (sortie du 04_)
captions_dict_path = config["captions_dict_path"]

with open(captions_dict_path, "r") as f:
    captions_dict = json.load(f)

# âœ… VÃ©rif dâ€™un ID dâ€™image + 5 captions associÃ©es
example_id = next(iter(captions_dict))
print(f"ğŸ“ Captions associÃ©es Ã  {example_id} :")
for cap in captions_dict[example_id]:
    print(" â¤", cap)

# ğŸ”„ GÃ©nÃ©ration des ID augmentÃ©s
augmentations = ["", "_aug0", "_aug1", "_aug2"]
full_pairs = []

for image_id, captions in captions_dict.items():
    for suffix in augmentations:
        full_id = image_id + suffix
        for caption in captions:
            full_pairs.append((full_id, caption))



dataset = ImageCaptionDataset(
    pairs=full_pairs,
    features_dir=config["features_dir"],
    tokenizer=tokenizer
)
collate_fn = get_collate_fn(tokenizer)


# ğŸ“ Proportions des splits
train_ratio = 0.8
val_ratio = 0.1
test_ratio = 0.1
total_size = len(dataset)

train_size = int(train_ratio * total_size)
val_size = int(val_ratio * total_size)
test_size = total_size - train_size - val_size  # le reste

# âœ‚ï¸ Split
train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])
print(f"ğŸ“Š Split â†’ Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}")

# ğŸ§ª DataLoaders

train_loader = DataLoader(train_dataset, batch_size=config["training"]["batch_size"], shuffle=True, num_workers=8, pin_memory=True, collate_fn=collate_fn)
val_loader = DataLoader(val_dataset, batch_size=config["training"]["batch_size"], shuffle=False, num_workers=8, pin_memory=True, collate_fn=collate_fn)
test_loader = DataLoader(test_dataset, batch_size=config["training"]["batch_size"], shuffle=False, num_workers=8, pin_memory=True, collate_fn=collate_fn)


# ğŸ§  ModÃ¨le
# ğŸ§  Initialisation
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
decoder = DecoderWithAttention(
    attention_dim=config["model"]["attention_dim"],
    embed_dim=config["model"]["embed_dim"],
    decoder_dim=config["model"]["decoder_dim"],
    vocab_size=tokenizer.vocab_size,
    dropout=config["model"]["dropout"]
).to(device)


# âš™ï¸ Optimiseur & CritÃ¨re
params = list(decoder.parameters())
optimizer = optim.Adam(params, lr=config["training"]["lr"])
criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)

# ğŸ‹ï¸ EntraÃ®nement
train_model(
    decoder=decoder,
    train_loader=train_loader,
    val_loader=val_loader,
    tokenizer=tokenizer,
    criterion=criterion,
    optimizer=optimizer,
    num_epochs=config["training"]["epochs"],
    patience=config["training"]["patience"]
)
