{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6983e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Nombre d'images avec l√©gendes : 8092\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "caption_file = Path(\"../data/raw/Flickr8k_text/Flickr8k.token.txt\")\n",
    "captions = defaultdict(list)\n",
    "\n",
    "with open(caption_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        img_id_full, caption = line.split('\\t')\n",
    "        img_id = img_id_full.split('#')[0]\n",
    "        captions[img_id].append(caption)\n",
    "\n",
    "print(f\"üìä Nombre d'images avec l√©gendes : {len(captions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e40fb251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Nombre d'images avec l√©gendes : 8092\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Dictionnaire image_id ‚Üí [liste de l√©gendes]\n",
    "captions = defaultdict(list)\n",
    "\n",
    "with open(caption_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        img_id_full, caption = line.split('\\t')\n",
    "        img_id = img_id_full.split('#')[0]\n",
    "        captions[img_id].append(caption)\n",
    "\n",
    "print(f\"üìä Nombre d'images avec l√©gendes : {len(captions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7343b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_caption(caption: str) -> str:\n",
    "    caption = caption.lower()\n",
    "    caption = re.sub(r\"[^a-z\\s]\", \"\", caption)  # supprime ponctuation, chiffres, accents\n",
    "    caption = re.sub(r\"\\s+\", \" \", caption).strip()  # normalise les espaces\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02ef6ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Image ID : 1000268201_693b08cb0e.jpg\n",
      "- <start> a child in a pink dress is climbing up a set of stairs in an entry way <end>\n",
      "- <start> a girl going into a wooden building <end>\n",
      "- <start> a little girl climbing into a wooden playhouse <end>\n",
      "- <start> a little girl climbing the stairs to her playhouse <end>\n",
      "- <start> a little girl in a pink dress going into a wooden cabin <end>\n"
     ]
    }
   ],
   "source": [
    "captions_cleaned = {}\n",
    "\n",
    "for img_id, caps in captions.items():\n",
    "    cleaned = [f\"<start> {clean_caption(c)} <end>\" for c in caps]\n",
    "    captions_cleaned[img_id] = cleaned\n",
    "\n",
    "# Affichage d‚Äôun exemple\n",
    "example_id = next(iter(captions_cleaned))\n",
    "print(\"üñºÔ∏è Image ID :\", example_id)\n",
    "for c in captions_cleaned[example_id]:\n",
    "    print(\"-\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4e3ae8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ 20 mots les plus fr√©quents :\n",
      "[('a', 62989), ('<start>', 40460), ('<end>', 40460), ('in', 18975), ('the', 18419), ('on', 10744), ('is', 9345), ('and', 8852), ('dog', 8136), ('with', 7765), ('man', 7266), ('of', 6713), ('two', 5639), ('white', 3940), ('black', 3832), ('boy', 3581), ('are', 3505), ('woman', 3403), ('girl', 3328), ('to', 3173)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Extraire tous les mots de toutes les l√©gendes\n",
    "all_captions = []\n",
    "for caps in captions_cleaned.values():\n",
    "    all_captions.extend(caps)\n",
    "\n",
    "# Tokenisation simple par split()\n",
    "words = []\n",
    "for cap in all_captions:\n",
    "    words.extend(cap.split())\n",
    "\n",
    "# Compter les mots\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# Afficher les plus fr√©quents\n",
    "print(\"üî¢ 20 mots les plus fr√©quents :\")\n",
    "print(word_counts.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad90d078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Taille finale du vocabulaire : 2988\n"
     ]
    }
   ],
   "source": [
    "# Hyperparam√®tre : fr√©quence minimale\n",
    "min_word_freq = 5\n",
    "\n",
    "# Vocabulaire filtr√©\n",
    "vocab = [word for word, count in word_counts.items() if count >= min_word_freq]\n",
    "\n",
    "# Ajout de tokens sp√©ciaux\n",
    "vocab = ['<pad>', '<unk>'] + sorted(vocab)\n",
    "\n",
    "# Dictionnaires\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "print(f\"üìö Taille finale du vocabulaire : {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "becb2f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tokenizer sauvegard√© dans : ../data/vocab/tokenizer.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "tokenizer_path = Path(\"../data/vocab/tokenizer.pkl\")\n",
    "tokenizer_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(tokenizer_path, \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"word2idx\": word2idx,\n",
    "        \"idx2word\": idx2word,\n",
    "        \"vocab\": vocab,\n",
    "        \"min_freq\": min_word_freq\n",
    "    }, f)\n",
    "\n",
    "print(\"‚úÖ Tokenizer sauvegard√© dans :\", tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a4ce2a",
   "metadata": {},
   "source": [
    "# Test du vocab "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1ed944",
   "metadata": {},
   "source": [
    "## √âtape 1 ‚Äî Charger le tokenizer sauvegard√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af5f209c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Taille du vocab : 2988\n",
      "üß† Extrait : ['<pad>', '<unk>', '<end>', '<start>', 'a', 'abandoned', 'about', 'above', 'accordion', 'acrobatic']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "with open(Path(\"../data/vocab/tokenizer.pkl\"), \"rb\") as f:\n",
    "    tokenizer_data = pickle.load(f)\n",
    "\n",
    "word2idx = tokenizer_data[\"word2idx\"]\n",
    "idx2word = tokenizer_data[\"idx2word\"]\n",
    "vocab = tokenizer_data[\"vocab\"]\n",
    "\n",
    "print(\"üî¢ Taille du vocab :\", len(vocab))\n",
    "print(\"üß† Extrait :\", vocab[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee779fe",
   "metadata": {},
   "source": [
    "## √âtape 2 ‚Äî Tester l‚Äôencodage d‚Äôune l√©gende"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5ee3ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Caption : <start> a man is riding a bicycle <end>\n",
      "üî¢ Encod√©e : [3, 4, 1517, 1309, 2096, 4, 222, 2]\n"
     ]
    }
   ],
   "source": [
    "def encode_caption(caption, word2idx):\n",
    "    return [word2idx.get(word, word2idx[\"<unk>\"]) for word in caption.split()]\n",
    "    \n",
    "sample_caption = \"<start> a man is riding a bicycle <end>\"\n",
    "encoded = encode_caption(sample_caption, word2idx)\n",
    "\n",
    "print(\"üßæ Caption :\", sample_caption)\n",
    "print(\"üî¢ Encod√©e :\", encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5231f0ef",
   "metadata": {},
   "source": [
    "## √âtape 3 ‚Äî Tester le d√©codage inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a30a6cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ D√©cod√©e : <start> a man is riding a bicycle <end>\n"
     ]
    }
   ],
   "source": [
    "def decode_caption(indices, idx2word):\n",
    "    return \" \".join([idx2word.get(idx, \"<unk>\") for idx in indices])\n",
    "\n",
    "print(\"üîÅ D√©cod√©e :\", decode_caption(encoded, idx2word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38db01b0",
   "metadata": {},
   "source": [
    "## √âtape 4 ‚Äî V√©rifier des cas particuliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e407275d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Token '<start>' : 3\n",
      "üîç Token '<pad>' : 0\n",
      "üîç Mot rare inconnu : 761\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç Token '<start>' :\", word2idx[\"<start>\"])\n",
    "print(\"üîç Token '<pad>' :\", word2idx[\"<pad>\"])\n",
    "print(\"üîç Mot rare inconnu :\", word2idx.get(\"dragon\", word2idx[\"<unk>\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881530da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
